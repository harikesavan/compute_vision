{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-12-6 Python-3.10.8 torch-1.13.0 CUDA:0 (NVIDIA GeForce GTX 1080, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "#load the torch model\n",
    "model = torch.hub.load('../yolov5', 'custom', path='../yolov5/best2.pt', source='local')\n",
    "#set min confidence \n",
    "model.conf = 0.75\n",
    "\n",
    "#other options are \n",
    "    #iou = 0.45  # NMS IoU threshold\n",
    "    #agnostic = False  # NMS class-agnostic\n",
    "    #multi_label = False  # NMS multiple labels per box\n",
    "    #classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "    #max_det = 1000  # maximum number of detections per image\n",
    "    #amp = False  # Automatic Mixed Precision (AMP) inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_000.mp4\n",
      "Wrote video video_000.mp4\n",
      "video_001.mp4\n",
      "Wrote video video_001.mp4\n",
      "video_002.mp4\n",
      "Wrote video video_002.mp4\n",
      "video_003.mp4\n",
      "Wrote video video_003.mp4\n",
      "video_004.mp4\n",
      "Wrote video video_004.mp4\n",
      "video_005.mp4\n",
      "Wrote video video_005.mp4\n",
      "video_006.mp4\n",
      "Wrote video video_006.mp4\n",
      "video_007.mp4\n",
      "Wrote video video_007.mp4\n",
      "video_008.mp4\n",
      "Wrote video video_008.mp4\n",
      "video_009.mp4\n",
      "Wrote video video_009.mp4\n",
      "video_010.mp4\n",
      "Wrote video video_010.mp4\n",
      "video_011.mp4\n",
      "Wrote video video_011.mp4\n",
      "video_012.mp4\n",
      "Wrote video video_012.mp4\n",
      "video_013.mp4\n",
      "Wrote video video_013.mp4\n",
      "video_014.mp4\n",
      "Wrote video video_014.mp4\n",
      "video_015.mp4\n",
      "Wrote video video_015.mp4\n",
      "video_016.mp4\n",
      "Wrote video video_016.mp4\n",
      "video_017.mp4\n",
      "Wrote video video_017.mp4\n",
      "video_018.mp4\n",
      "Wrote video video_018.mp4\n",
      "video_019.mp4\n",
      "Wrote video video_019.mp4\n",
      "video_020.mp4\n",
      "Wrote video video_020.mp4\n",
      "video_021.mp4\n",
      "Wrote video video_021.mp4\n",
      "video_022.mp4\n",
      "Wrote video video_022.mp4\n",
      "video_023.mp4\n",
      "Wrote video video_023.mp4\n",
      "video_024.mp4\n",
      "Wrote video video_024.mp4\n",
      "video_025.mp4\n",
      "Wrote video video_025.mp4\n",
      "video_026.mp4\n",
      "Wrote video video_026.mp4\n",
      "video_027.mp4\n",
      "Wrote video video_027.mp4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "for path in glob.glob(\"../data_target_tracking/*.mp4\"):\n",
    "    video_name = os.path.basename(path) \n",
    "    print(video_name)\n",
    "   \n",
    "\n",
    "\n",
    "    out = cv.VideoWriter(video_name,cv.VideoWriter_fourcc(*'MP4V'), 30, (640,512))\n",
    "    cap = cv.VideoCapture(path)\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()  \n",
    "        if ret:\n",
    "            result = model(frame)\n",
    "            img = np.array(result.render()).squeeze()\n",
    "            #cv.imshow(\"Test\",img)\n",
    "            out.write(img)\n",
    "            #if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "                #break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    #cv.destroyAllWindows()\n",
    "    print(\"Wrote video \" + video_name)\n",
    "    \n",
    " \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real time inference\n",
    "#interrupt video with q\n",
    "video_path = \"../data_target_tracking/video_015.mp4\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()  \n",
    "    \n",
    "    if ret:\n",
    "        result = model(frame)\n",
    "        img = np.array(result.render()).squeeze()\n",
    "        cv.imshow(\"Test\",img)\n",
    "        out.write(img)\n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "   \n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222.102478</td>\n",
       "      <td>259.039001</td>\n",
       "      <td>236.239929</td>\n",
       "      <td>272.750793</td>\n",
       "      <td>0.708632</td>\n",
       "      <td>0</td>\n",
       "      <td>oc_person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin        xmax        ymax  confidence  class  \\\n",
       "0  222.102478  259.039001  236.239929  272.750793    0.708632      0   \n",
       "\n",
       "        name  \n",
       "0  oc_person  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How to find the bounding boxes\n",
    "result.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d7b52c4fc7382a0918a8ab07ad0be40fd08fbe3cce6a9e302bbf7a54e400715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
